#!/usr/bin/env python3
"""
BHXH Penetration Testing - Final Analysis Report Generator
Comprehensive analysis of all collected evidence and vulnerabilities
"""

import json
import os
from datetime import datetime
from pathlib import Path
from bhxh_data_standardizer import BHXHDataStandardizer

class FinalAnalysisReporter:
    def __init__(self):
        self.base_dir = Path(".")
        self.evidence_dir = self.base_dir / "evidence"
        self.customer_dir = self.base_dir / "customer_data_evidence"
        self.session_dir = self.base_dir / "sessionstate_exploitation"
        
        # Initialize BHXH data standardizer
        self.data_standardizer = BHXHDataStandardizer()
        
        self.final_stats = {
            "total_vulnerabilities": 0,
            "critical_findings": [],
            "tokens_analyzed": 0,
            "customer_data_points": 0,
            "database_compromises": 0,
            "evidence_files": 0
        }

    def analyze_evidence_directory(self):
        """Analyze all evidence files in the evidence directory"""
        print(f"üìÅ Analyzing evidence directory: {self.evidence_dir}")
        
        exploit_files = 0
        sql_injection_count = 0
        database_errors = 0
        
        if self.evidence_dir.exists():
            exploits_dir = self.evidence_dir / "exploits"
            if exploits_dir.exists():
                for file in exploits_dir.iterdir():
                    if file.is_file():
                        exploit_files += 1
                        if "time_based_sqli" in file.name:
                            sql_injection_count += 1
                        elif "database_error" in file.name:
                            database_errors += 1
        
        self.final_stats["evidence_files"] = exploit_files
        self.final_stats["sql_injections"] = sql_injection_count
        self.final_stats["database_errors"] = database_errors
        
        print(f"[+] Evidence files found: {exploit_files}")
        print(f"[+] SQL injection proofs: {sql_injection_count}")
        print(f"[+] Database error evidences: {database_errors}")

    def analyze_token_data(self):
        """Analyze token and customer data from comprehensive analysis"""
        token_file = self.base_dir / "TOKEN_DATA_COMPREHENSIVE_ANALYSIS.json"
        
        if token_file.exists():
            try:
                with open(token_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                self.final_stats["tokens_analyzed"] = data.get("summary", {}).get("total_tokens_found", 0)
                self.final_stats["customer_data_points"] = data.get("summary", {}).get("total_customer_data_points", 0)
                self.final_stats["database_exposures"] = data.get("summary", {}).get("total_database_exposures", 0)
                self.final_stats["session_data"] = data.get("summary", {}).get("total_session_data", 0)
                self.final_stats["total_vulnerabilities"] = data.get("summary", {}).get("total_vulnerabilities", 0)
                
                print(f"[+] Tokens analyzed: {self.final_stats['tokens_analyzed']}")
                print(f"[+] Customer data points: {self.final_stats['customer_data_points']}")
                print(f"[+] Database exposures: {self.final_stats['database_exposures']}")
                
            except Exception as e:
                print(f"[-] Error reading token analysis: {e}")

    def analyze_sessionstate_compromise(self):
        """Analyze SessionState database compromise evidence"""
        session_file = self.session_dir / "20250606_100508_COMPREHENSIVE_SESSIONSTATE_EXPLOITATION.json"
        
        if session_file.exists():
            try:
                with open(session_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                phases = data.get("exploitation_phases", [])
                total_findings = sum(phase.get("results_count", 0) for phase in phases)
                
                self.final_stats["sessionstate_findings"] = total_findings
                self.final_stats["database_compromises"] = 1 if total_findings > 0 else 0
                
                print(f"[+] SessionState findings: {total_findings}")
                print(f"[+] Database compromises: {self.final_stats['database_compromises']}")
                
                # Extract critical findings
                if total_findings > 0:
                    self.final_stats["critical_findings"].extend([
                        "SessionStateService_356ec96765eb4cc6b687ea3bb1be01c4 Database Compromised",
                        "BHXH\\sharepoint_portal User Account Compromised",
                        "ASP.NET Session Tokens Exposed"
                    ])
                    
            except Exception as e:
                print(f"[-] Error reading sessionstate analysis: {e}")

    def analyze_customer_data_breach(self):
        """Analyze customer data breach evidence"""
        customer_report = self.customer_dir / "customer_profiles" / "20250606_100743_COMPREHENSIVE_CUSTOMER_REPORT.json"
        
        if customer_report.exists():
            try:
                with open(customer_report, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                summary = data.get("summary", {})
                self.final_stats["affected_customers"] = summary.get("total_customers", 0)
                self.final_stats["complete_profiles"] = summary.get("complete_profiles", 0)
                self.final_stats["partial_profiles"] = summary.get("partial_profiles", 0)
                
                risk = data.get("risk_assessment", {})
                self.final_stats["data_exposure_level"] = risk.get("data_exposure_level", "UNKNOWN")
                self.final_stats["privacy_impact"] = risk.get("privacy_impact", "UNKNOWN")
                
                print(f"[+] Affected customers: {self.final_stats['affected_customers']}")
                print(f"[+] Data exposure level: {self.final_stats['data_exposure_level']}")
                
            except Exception as e:
                print(f"[-] Error reading customer data analysis: {e}")

    def calculate_risk_score(self):
        """Calculate overall risk score based on findings"""
        risk_score = 0
        
        # SQL Injection findings (high weight)
        risk_score += self.final_stats.get("sql_injections", 0) * 5
        
        # Database compromises (critical weight)
        risk_score += self.final_stats.get("database_compromises", 0) * 50
        
        # Token exposures (medium weight)
        risk_score += min(self.final_stats.get("tokens_analyzed", 0) / 10, 20)
        
        # Customer data exposure (high weight)
        risk_score += min(self.final_stats.get("customer_data_points", 0) / 100, 30)
        
        # Database errors (medium weight)
        risk_score += self.final_stats.get("database_errors", 0) * 2
        
        self.final_stats["risk_score"] = min(risk_score, 100)
        
        if risk_score >= 80:
            self.final_stats["risk_level"] = "CRITICAL"
        elif risk_score >= 60:
            self.final_stats["risk_level"] = "HIGH"
        elif risk_score >= 40:
            self.final_stats["risk_level"] = "MEDIUM"
        else:
            self.final_stats["risk_level"] = "LOW"

    def generate_final_report(self):
        """Generate comprehensive final analysis report"""
        timestamp = datetime.now().isoformat()
        
        report = {
            "penetration_testing_final_analysis": {
                "timestamp": timestamp,
                "target_system": "https://baohiemxahoi.gov.vn",
                "assessment_period": "2025-06-06 09:35 - 10:18",
                "overall_status": "ASSESSMENT COMPLETE - CRITICAL VULNERABILITIES FOUND"
            },
            "executive_summary": {
                "risk_level": self.final_stats.get("risk_level", "UNKNOWN"),
                "risk_score": f"{self.final_stats.get('risk_score', 0)}/100",
                "total_vulnerabilities": self.final_stats.get("total_vulnerabilities", 0),
                "critical_findings_count": len(self.final_stats.get("critical_findings", [])),
                "immediate_action_required": True if self.final_stats.get("risk_level") in ["CRITICAL", "HIGH"] else False
            },
            "detailed_findings": {
                "sql_injection": {
                    "instances_found": self.final_stats.get("sql_injections", 0),
                    "type": "Time-based SQL Injection",
                    "severity": "CRITICAL",
                    "exploitable": True
                },
                "database_compromise": {
                    "databases_affected": self.final_stats.get("database_compromises", 0),
                    "database_name": "SessionStateService_356ec96765eb4cc6b687ea3bb1be01c4",
                    "user_compromised": "BHXH\\sharepoint_portal",
                    "severity": "CRITICAL"
                },
                "token_exposure": {
                    "tokens_collected": self.final_stats.get("tokens_analyzed", 0),
                    "session_data_leaked": self.final_stats.get("session_data", 0),
                    "severity": "HIGH"
                },
                "customer_data_breach": {
                    "data_points_exposed": self.final_stats.get("customer_data_points", 0),
                    "customers_affected": self.final_stats.get("affected_customers", 0),
                    "exposure_level": self.final_stats.get("data_exposure_level", "UNKNOWN"),
                    "severity": "HIGH"
                }
            },
            "evidence_summary": {
                "total_evidence_files": self.final_stats.get("evidence_files", 0),
                "exploitation_proofs": self.final_stats.get("sql_injections", 0),
                "database_error_captures": self.final_stats.get("database_errors", 0),
                "sessionstate_compromise_files": 1 if self.final_stats.get("sessionstate_findings", 0) > 0 else 0,
                "customer_data_evidence_files": 1
            },
            "compliance_impact": {
                "vietnam_cybersecurity_law": "VIOLATION",
                "personal_data_protection": "VIOLATION", 
                "insurance_regulations": "VIOLATION",
                "iso_27001": "MAJOR_NON_CONFORMITY",
                "gdpr_applicable": "POTENTIAL_VIOLATION"
            },
            "recommendations": {
                "immediate_actions": [
                    "Disconnect vulnerable database systems",
                    "Reset all exposed session tokens",
                    "Disable SQL injection endpoints",
                    "Activate incident response team"
                ],
                "short_term_actions": [
                    "Patch all SQL injection vulnerabilities",
                    "Rebuild SessionStateService database",
                    "Implement input validation",
                    "Notify affected customers"
                ],
                "long_term_actions": [
                    "Full security audit",
                    "Penetration testing verification", 
                    "Staff security training",
                    "Compliance review"
                ]
            },
            "final_statistics": self.final_stats
        }
        
        # Save final report
        report_file = self.base_dir / f"FINAL_COMPREHENSIVE_ANALYSIS_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìä FINAL ANALYSIS COMPLETE")
        print(f"[+] Report saved: {report_file}")
        print(f"[+] Risk Level: {self.final_stats.get('risk_level', 'UNKNOWN')}")
        print(f"[+] Risk Score: {self.final_stats.get('risk_score', 0)}/100")
        
        return report

    def run_final_analysis(self):
        """Run complete final analysis"""
        print("üöÄ Starting Final Penetration Testing Analysis...")
        print("=" * 60)
        
        # Analyze all evidence
        self.analyze_evidence_directory()
        print()
        self.analyze_token_data()
        print()
        self.analyze_sessionstate_compromise()
        print()
        self.analyze_customer_data_breach()
        print()
        
        # Calculate risk
        self.calculate_risk_score()
        print(f"üìä Calculated Risk Score: {self.final_stats['risk_score']}/100 - {self.final_stats['risk_level']}")
        print()
        
        # Generate final report
        final_report = self.generate_final_report()
        
        print("\n" + "=" * 60)
        print("üéØ PENETRATION TESTING ASSESSMENT COMPLETE")
        print("=" * 60)
        
        return final_report

if __name__ == "__main__":
    print("BHXH Penetration Testing - Final Analysis")
    print("Generated:", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    print("=" * 60)
    
    analyzer = FinalAnalysisReporter()
    final_report = analyzer.run_final_analysis()
    
    print(f"\n‚úÖ All analysis complete!")
    print(f"üìÅ Evidence directories: 3 main directories analyzed")
    print(f"üîç Files processed: {final_report['evidence_summary']['total_evidence_files']} evidence files")
    print(f"‚ö†Ô∏è  Critical findings: {len(final_report['detailed_findings'])} categories")
    print(f"üö® Action required: {'YES - IMMEDIATE' if final_report['executive_summary']['immediate_action_required'] else 'NO'}")
